{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e77f0d51-3fad-4ae8-a1e0-65ec5bfc7c5f",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d6932de-8fb7-4b60-aa9f-b4c574202a99",
   "metadata": {},
   "source": [
    "#### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67c44f56-bd0a-46a5-8011-6477eeda77ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/ubuntu/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "2024-03-14 16:28:11.309239: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-14 16:28:12.969920: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import json, os, re\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "from typing import List, Dict, Any, Set\n",
    "\n",
    "import numpy as np\n",
    "np.int = np.int32\n",
    "np.float = np.float64\n",
    "np.bool = np.bool_\n",
    "\n",
    "import nltk as nltk_lib\n",
    "nltk_lib.download('punkt')\n",
    "\n",
    "import tokenizations\n",
    "from textspan import get_original_spans\n",
    "from clinitokenizer.tokenize import clini_tokenize\n",
    "\n",
    "from deid_utils import assign_sentence_id, satisfies_regex_rule, REGEX_PATTERNS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c2e840-8166-499d-aa74-ef2f86057c7c",
   "metadata": {},
   "source": [
    "#### Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d161f30-cc33-41f8-a5d2-bb21bbe71473",
   "metadata": {},
   "outputs": [],
   "source": [
    "JsonType = List[Dict[str, Any]]\n",
    "\n",
    "path = \"../sc/NER_data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e20c2893-35b1-485f-a712-a0458c531567",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(path: str) -> Dict[str, JsonType]:\n",
    "    json_data: Dict[str, JsonType] = {}\n",
    "    \n",
    "    for filename in os.listdir(path):\n",
    "        if filename.endswith('.json'):\n",
    "            filepath = os.path.join(path, filename)\n",
    "            \n",
    "            with open(filepath, 'r', encoding=\"utf-8\") as file:\n",
    "                json_data[filename] = json.load(file)\n",
    "    return json_data\n",
    "\n",
    "json_data = get_data(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d41818-fbb2-441a-918e-eb18fe4fe4d2",
   "metadata": {},
   "source": [
    "#### Join files, filter and harmonize annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a29822b1-f9ee-4e63-8f16-f3f51fd554a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simplify_json_structure(file: JsonType) -> JsonType:  \n",
    "    \"\"\"\n",
    "    This function filters elements in the structure of the input json file \n",
    "    and returns its' simplified version. It filters the following fields:\n",
    "        - \"id\"\n",
    "        - \"data\"\n",
    "        - raw \"annonations\" (i.e., the results)\n",
    "    \"\"\"\n",
    "    simplified: JsonType = [{} for _ in range(len(file))]\n",
    "    \n",
    "    for i, record in enumerate(file):\n",
    "        simplified[i][\"id\"] = record[\"id\"]\n",
    "        simplified[i][\"data\"] = record[\"data\"]\n",
    "\n",
    "        annotations: List[Dict[Dict[str, Any]]] = []\n",
    "        for annotation in record[\"annotations\"][0][\"result\"]:\n",
    "            result: Dict[str, Any] = annotation[\"value\"]\n",
    "            annotations.append(result)\n",
    "            \n",
    "        simplified[i][\"annotations\"] = annotations\n",
    "    return simplified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "235edf40-5beb-4db1-8c46-d5420474a30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_anonymisation_anno(file: JsonType) -> None:\n",
    "    \"\"\"\n",
    "    This function filters through the annotated entities in text\n",
    "    and only keeps the ones labeled for anonymization.\n",
    "    \"\"\"\n",
    "    for record in file:\n",
    "        filtered: List[Dict[str, Any]] = []\n",
    "        \n",
    "        for annotation in record[\"annotations\"]:\n",
    "            if annotation[\"labels\"][0] == \"anonymizovat\":\n",
    "                filtered.append(annotation)\n",
    "\n",
    "        record[\"annotations\"] = filtered    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "17a23041-7947-4e67-b725-52dc1d3258b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename, file in json_data.items():\n",
    "    json_data[filename] = simplify_json_structure(file)\n",
    "    filter_anonymisation_anno(json_data[filename])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "db37d5d9-ffb9-4bf2-9633-101f16f27933",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(json.dumps(json_data[\"fin_ann1.json\"], ensure_ascii = False, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a8a9cf68-1c70-47f7-9a09-c8c31b86b533",
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename, file in json_data.items():\n",
    "    path = os.path.join(\"/workspace/home/\", filename)\n",
    "    with open(path, \"w\") as json_file:\n",
    "        json.dump(file, json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d3719904-7ddf-4f8a-93d2-f093a36b5b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_anno_statistics(file: JsonType) -> None:\n",
    "    count = 0\n",
    "    ids: List[num] = []\n",
    "    \n",
    "    for record in file:\n",
    "        if len(record[\"annotations\"]) > 0:\n",
    "            count += 1\n",
    "            ids.append(record[\"id\"])\n",
    "    print(f'\\t-number of annotated records = {count}')\n",
    "    print(f'\\t-ids of the annotated records = {ids}')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9b33b5d2-358f-4ebf-8ec6-03eaf8b02c60",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fin_ann1.json (40 items):\n",
      "\t-number of annotated records = 0\n",
      "\t-ids of the annotated records = []\n",
      "fin_ann3.json (40 items):\n",
      "\t-number of annotated records = 11\n",
      "\t-ids of the annotated records = [42, 44, 46, 47, 48, 49, 50, 51, 52, 53, 54]\n",
      "fin_ann2.json (40 items):\n",
      "\t-number of annotated records = 1\n",
      "\t-ids of the annotated records = [82]\n"
     ]
    }
   ],
   "source": [
    "for filename, file in json_data.items():\n",
    "    print(f'{filename} ({len(file)} items):')\n",
    "    print_anno_statistics(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "138284f3-c426-401d-9b15-d4786cf63972",
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_files(json_data: Dict[str, JsonType]) -> JsonType:\n",
    "    \"\"\"\n",
    "    Annotated files include text duplicates.\n",
    "    This function joins all unique records from all the files. \n",
    "    \"\"\"\n",
    "    joined_json_data: JsonType = []\n",
    "    texts_metadata: Set[Tuple[str, str, str]] = set()\n",
    "    duplicates_count, unique_count = 0, 0\n",
    "\n",
    "    for filename in sorted(json_data.keys(), reverse=True):  # all annotations are in the last file \"fin_ann3.json\"\n",
    "        for record in json_data[filename]:\n",
    "\n",
    "            # (i, pid, rord) are unique for each text\n",
    "            i = record[\"data\"][\"i\"] if \"i\" in record[\"data\"].keys() else None\n",
    "            pid = record[\"data\"][\"pid\"] if \"pid\" in record[\"data\"].keys() else None\n",
    "            rord = record[\"data\"][\"rord\"] if \"rord\" in record[\"data\"].keys() else None\n",
    "            metadata = (i, pid, rord)\n",
    "\n",
    "            if i is None or pid is None or rord is None:  # edge case (e.g. holds for record with id=82)\n",
    "                duplicates_count += 1\n",
    "                continue\n",
    "\n",
    "            if metadata not in texts_metadata:  # unique record\n",
    "                joined_json_data.append(record)\n",
    "                texts_metadata.add(metadata)     \n",
    "                unique_count += 1\n",
    "            else:\n",
    "                duplicates_count += 1\n",
    "    \n",
    "    print(f'number of unique records: {unique_count}')\n",
    "    print(f'number of duplicated records: {duplicates_count}')\n",
    "    print(\"all the records == duplicated + unique\", end=' ')\n",
    "    print(f'{sum(len(x) for x in json_data.values()) == unique_count + duplicates_count}\\n')\n",
    "\n",
    "    joined_json_data.sort(key=lambda x: x[\"id\"])\n",
    "    return joined_json_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "72cd90e6-a2b2-4f7b-9f54-0bba29b7afe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of unique records: 80\n",
      "number of duplicated records: 40\n",
      "all the records == duplicated + unique True\n",
      "\n",
      "joined_json_data (80 items):\n",
      "\t-number of annotated records = 11\n",
      "\t-ids of the annotated records = [42, 44, 46, 47, 48, 49, 50, 51, 52, 53, 54]\n"
     ]
    }
   ],
   "source": [
    "joined_json_data: JsonType = join_files(json_data)\n",
    "\n",
    "print(f'joined_json_data ({len(joined_json_data)} items):')\n",
    "print_anno_statistics(joined_json_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "380fbea2-f9c6-4850-af2b-36128500ceb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"joined_data.json\", \"w\") as file:\n",
    "    json.dump(joined_json_data, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e5e8638-3147-4b74-8ff5-ada9a2169194",
   "metadata": {},
   "source": [
    "#### ... Annotation of the rest of the dataset ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "37b27de9-d67e-49ee-b128-7966b1044ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"joined_data_annotated.json\", 'r', encoding=\"utf-8\") as file:\n",
    "    json_data = json.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e947ccec-9369-40da-a835-6d5dbcfa9479",
   "metadata": {},
   "source": [
    "#### Json to CSV with Ground Truth and Regex Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bb9591a9-a35e-4c8b-9256-45f956cf2f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_words(record: Dict[str, Any], temp: DataFrame) -> None:\n",
    "    \"\"\"\n",
    "    This function puts labels to the individual words from the record that is \n",
    "    taken as an input according to the annotations provided (in the record).\n",
    "    The result is stored in the dataframe that it takes as an input.\n",
    "    \"\"\"\n",
    "    for annotation in record['annotations']:\n",
    "        start, end = annotation[\"start\"], annotation[\"end\"]\n",
    "        selected_rows = temp[(temp[\"start\"] >= start) & (temp[\"end\"] <= end)]\n",
    "        temp.loc[selected_rows.index, \"true_label\"] = \"A\"\n",
    "        \n",
    "    temp[\"true_label\"].fillna(\"O\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2d008cc0-bfb1-491e-aa1d-3386cee3a9c8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenizing sentences:   0%|                                                         | 0/767 [00:00<?, ?it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:   2%|▉                                               | 15/767 [00:02<02:15,  5.54it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:   4%|█▉                                              | 30/767 [00:04<01:44,  7.04it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:   6%|██▊                                             | 44/767 [00:06<01:44,  6.90it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:   8%|███▋                                            | 58/767 [00:08<01:34,  7.48it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:   9%|████▌                                           | 72/767 [00:09<01:30,  7.67it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  11%|█████▎                                          | 85/767 [00:11<01:30,  7.51it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  13%|██████                                          | 97/767 [00:13<01:30,  7.40it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  14%|██████▊                                        | 111/767 [00:15<01:25,  7.70it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  16%|███████▋                                       | 126/767 [00:16<01:19,  8.04it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  18%|████████▌                                      | 140/767 [00:18<01:17,  8.07it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  33%|███████████████▌                               | 253/767 [00:24<00:32, 15.92it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  35%|████████████████▍                              | 269/767 [00:26<00:37, 13.22it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  11%|█████▍                                          | 61/533 [00:01<00:12, 37.83it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  14%|██████▊                                         | 75/533 [00:03<00:25, 17.72it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  17%|████████                                        | 90/533 [00:05<00:32, 13.56it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  20%|█████████▏                                     | 104/533 [00:07<00:38, 11.23it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  22%|██████████▍                                    | 119/533 [00:08<00:39, 10.40it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  25%|███████████▌                                   | 131/533 [00:10<00:43,  9.32it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  27%|████████████▊                                  | 145/533 [00:12<00:44,  8.74it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  30%|██████████████                                 | 159/533 [00:14<00:44,  8.42it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  33%|███████████████▎                               | 174/533 [00:15<00:42,  8.46it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  35%|████████████████▌                              | 188/533 [00:17<00:41,  8.41it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  66%|██████████████████████████████▉                | 351/533 [00:23<00:06, 26.27it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:   0%|                                                         | 0/368 [00:00<?, ?it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:   2%|▊                                                | 6/368 [00:01<01:47,  3.36it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:   6%|██▊                                             | 22/368 [00:03<00:52,  6.55it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:   8%|███▊                                            | 29/368 [00:05<01:03,  5.30it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  67%|███████████████████████████████▎               | 245/368 [00:14<00:04, 28.05it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  70%|████████████████████████████████▉              | 258/368 [00:16<00:05, 18.54it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:   0%|                                                         | 0/478 [00:00<?, ?it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:   3%|█▌                                              | 15/478 [00:01<00:53,  8.66it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:   6%|███                                             | 30/478 [00:03<00:50,  8.80it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:   9%|████▎                                           | 43/478 [00:05<00:53,  8.20it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  12%|█████▊                                          | 58/478 [00:07<00:52,  8.06it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  15%|███████▏                                        | 72/478 [00:08<00:50,  8.02it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  33%|███████████████▋                               | 162/485 [00:05<00:10, 29.86it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  59%|███████████████████████████▌                   | 285/485 [00:10<00:06, 28.79it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  10%|████▋                                           | 31/319 [00:00<00:07, 38.52it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  15%|███████                                         | 47/319 [00:02<00:16, 16.04it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  19%|█████████▎                                      | 62/319 [00:04<00:21, 12.08it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  24%|███████████▌                                    | 77/319 [00:05<00:22, 10.94it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  25%|████████████▏                                   | 81/319 [00:07<00:32,  7.43it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  30%|██████████████▌                                 | 97/319 [00:09<00:29,  7.65it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:   0%|                                                         | 0/705 [00:00<?, ?it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:   2%|█                                               | 15/705 [00:01<01:26,  7.96it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:   4%|█▉                                              | 28/705 [00:03<01:31,  7.42it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:   6%|██▉                                             | 43/705 [00:05<01:24,  7.82it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:   8%|███▉                                            | 57/705 [00:07<01:20,  8.06it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  10%|████▊                                           | 71/705 [00:08<01:18,  8.11it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  12%|█████▊                                          | 85/705 [00:10<01:17,  8.01it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  14%|██████▋                                        | 100/705 [00:12<01:13,  8.23it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  16%|███████▌                                       | 113/705 [00:14<01:13,  8.02it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  18%|████████▌                                      | 128/705 [00:15<01:11,  8.08it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  20%|█████████▍                                     | 142/705 [00:17<01:13,  7.68it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  22%|██████████▎                                    | 155/705 [00:19<01:14,  7.43it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  44%|████████████████████▋                          | 311/705 [00:26<00:15, 25.37it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:   0%|                                                         | 0/476 [00:00<?, ?it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:   3%|█▍                                              | 14/476 [00:01<01:03,  7.24it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:   6%|██▉                                             | 29/476 [00:03<00:56,  7.93it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:   9%|████▎                                           | 43/476 [00:05<00:57,  7.58it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  12%|█████▊                                          | 58/476 [00:07<00:53,  7.88it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  15%|███████▎                                        | 73/476 [00:09<00:51,  7.84it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  18%|████████▊                                       | 88/476 [00:11<00:48,  8.01it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  21%|██████████                                     | 102/476 [00:12<00:46,  7.99it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  24%|███████████▍                                   | 116/476 [00:14<00:45,  7.91it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  27%|████████████▊                                  | 130/476 [00:16<00:44,  7.76it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  30%|██████████████                                 | 143/476 [00:18<00:43,  7.71it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  50%|███████████████████████▍                       | 237/476 [00:22<00:12, 18.97it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:   5%|██▍                                            | 51/1004 [00:01<00:32, 29.70it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:   6%|██▉                                            | 64/1004 [00:03<00:59, 15.81it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:   8%|███▋                                           | 79/1004 [00:05<01:14, 12.49it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:   9%|████▎                                          | 93/1004 [00:07<01:26, 10.54it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  11%|████▊                                         | 106/1004 [00:08<01:38,  9.11it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  12%|█████▍                                        | 118/1004 [00:10<01:45,  8.37it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  13%|██████                                        | 132/1004 [00:12<01:46,  8.15it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  15%|██████▋                                       | 146/1004 [00:14<01:46,  8.05it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  16%|███████▍                                      | 161/1004 [00:16<01:44,  8.07it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  17%|████████                                      | 175/1004 [00:17<01:42,  8.06it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  69%|███████████████████████████████▊              | 693/1004 [00:38<00:12, 24.78it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  71%|████████████████████████████████▍             | 709/1004 [00:40<00:16, 17.59it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "WARNING:root:Buffer size reduced to 8 for iteration.\n",
      "WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "WARNING:root:Buffer size reduced to 8 for iteration.\n",
      "Tokenizing sentences:  71%|████████████████████████████████▊             | 717/1004 [00:45<00:41,  6.93it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "WARNING:root:Buffer size reduced to 8 for iteration.\n",
      "WARNING:root:Buffer size reduced to 4 for iteration.\n",
      "Tokenizing sentences:  72%|█████████████████████████████████             | 721/1004 [00:49<01:03,  4.48it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "WARNING:root:Buffer size reduced to 8 for iteration.\n",
      "WARNING:root:Buffer size reduced to 4 for iteration.\n",
      "WARNING:root:Buffer size reduced to 2 for iteration.\n",
      "Tokenizing sentences:  72%|█████████████████████████████████▏            | 723/1004 [00:54<01:40,  2.81it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "WARNING:root:Buffer size reduced to 8 for iteration.\n",
      "WARNING:root:Buffer size reduced to 4 for iteration.\n",
      "WARNING:root:Buffer size reduced to 2 for iteration.\n",
      "WARNING:root:Buffer size reduced to 1 for iteration.\n",
      "Tokenizing sentences:  84%|██████████████████████████████████████▊       | 848/1004 [01:05<00:10, 14.99it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  86%|███████████████████████████████████████▌      | 864/1004 [01:07<00:10, 12.78it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  20%|█████████▎                                     | 117/593 [00:04<00:17, 27.19it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  50%|███████████████████████▍                       | 295/593 [00:12<00:10, 28.81it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  52%|████████████████████████▌                      | 310/593 [00:14<00:14, 19.72it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  17%|████████                                       | 130/758 [00:05<00:23, 27.12it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  19%|████████▊                                      | 143/758 [00:07<00:36, 16.85it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  21%|█████████▊                                     | 158/758 [00:09<00:44, 13.59it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  23%|██████████▋                                    | 173/758 [00:10<00:48, 12.01it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  25%|███████████▌                                   | 186/758 [00:12<00:55, 10.31it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  27%|████████████▍                                  | 201/758 [00:14<00:59,  9.36it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  28%|█████████████▏                                 | 213/758 [00:16<01:03,  8.54it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  30%|██████████████▏                                | 228/758 [00:18<01:06,  7.95it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  32%|██████████████▉                                | 241/758 [00:20<01:06,  7.73it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  34%|███████████████▊                               | 256/758 [00:22<01:07,  7.49it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  35%|████████████████▋                              | 269/758 [00:24<01:06,  7.40it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  37%|█████████████████▌                             | 284/758 [00:26<01:03,  7.41it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  39%|██████████████████▍                            | 298/758 [00:28<01:02,  7.33it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  41%|███████████████████                            | 307/758 [00:29<01:06,  6.79it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  42%|███████████████████▉                           | 321/758 [00:31<01:02,  7.02it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  44%|████████████████████▊                          | 335/758 [00:33<00:57,  7.39it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  46%|█████████████████████▌                         | 347/758 [00:35<00:59,  6.91it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  48%|██████████████████████▍                        | 361/758 [00:37<00:54,  7.23it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  15%|██████▊                                        | 128/877 [00:04<00:27, 27.17it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  16%|███████▌                                       | 142/877 [00:06<00:43, 16.86it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  18%|████████▍                                      | 157/877 [00:08<00:53, 13.46it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  20%|█████████▏                                     | 172/877 [00:10<01:04, 11.00it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  21%|██████████                                     | 187/877 [00:12<01:07, 10.16it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  23%|██████████▊                                    | 202/877 [00:14<01:11,  9.39it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  25%|███████████▋                                   | 217/877 [00:16<01:12,  9.05it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  26%|████████████▍                                  | 232/877 [00:18<01:14,  8.69it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  28%|█████████████▏                                 | 246/877 [00:20<01:16,  8.21it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  30%|█████████████▉                                 | 260/877 [00:22<01:16,  8.03it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  31%|██████████████▋                                | 274/877 [00:23<01:14,  8.07it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  33%|███████████████▍                               | 287/877 [00:25<01:15,  7.82it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  34%|████████████████                               | 299/877 [00:27<01:19,  7.25it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  36%|████████████████▊                              | 313/877 [00:29<01:14,  7.53it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  22%|██████████▍                                     | 88/403 [00:02<00:09, 33.43it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:   0%|                                                         | 0/353 [00:00<?, ?it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:   4%|██                                              | 15/353 [00:01<00:38,  8.80it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:   8%|███▉                                            | 29/353 [00:03<00:39,  8.30it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  12%|█████▉                                          | 44/353 [00:05<00:36,  8.43it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  17%|████████                                        | 59/353 [00:07<00:35,  8.40it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:   0%|                                                         | 0/417 [00:00<?, ?it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:   4%|█▋                                              | 15/417 [00:01<00:51,  7.73it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:   7%|███▎                                            | 29/417 [00:03<00:48,  8.07it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  11%|█████                                           | 44/417 [00:05<00:45,  8.21it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  14%|██████▊                                         | 59/417 [00:07<00:44,  8.03it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:   0%|                                                         | 0/358 [00:00<?, ?it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:   4%|██                                              | 15/358 [00:01<00:41,  8.31it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:   8%|███▉                                            | 29/358 [00:03<00:41,  7.96it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  12%|█████▉                                          | 44/358 [00:05<00:38,  8.17it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  16%|███████▉                                        | 59/358 [00:07<00:35,  8.38it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  24%|███████████▋                                    | 87/358 [00:09<00:28,  9.50it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:   0%|                                                         | 0/465 [00:00<?, ?it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:   3%|█▌                                              | 15/465 [00:01<00:57,  7.85it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:   6%|███                                             | 30/465 [00:03<00:52,  8.30it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:   9%|████▌                                           | 44/465 [00:05<00:53,  7.90it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  12%|█████▉                                          | 58/465 [00:07<00:53,  7.58it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  15%|███████▍                                        | 72/465 [00:09<00:51,  7.62it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  18%|████████▉                                       | 86/465 [00:11<00:49,  7.63it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  21%|██████████▏                                     | 99/465 [00:12<00:47,  7.65it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  24%|███████████▍                                   | 113/465 [00:14<00:46,  7.49it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  37%|█████████████████▏                             | 170/465 [00:18<00:21, 13.76it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  46%|█████████████████████▍                         | 212/465 [00:21<00:16, 15.73it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  47%|██████████████████████▏                        | 219/465 [00:22<00:21, 11.55it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  37%|█████████████████▌                             | 274/733 [00:11<00:17, 25.70it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  39%|██████████████████▌                            | 289/733 [00:13<00:26, 17.01it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  41%|███████████████████▎                           | 301/733 [00:14<00:33, 12.92it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  43%|████████████████████▏                          | 315/733 [00:16<00:39, 10.53it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  45%|█████████████████████                          | 329/733 [00:18<00:41,  9.64it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  47%|█████████████████████▊                         | 341/733 [00:20<00:45,  8.55it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  71%|█████████████████████████████████▎             | 520/733 [00:27<00:07, 28.02it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  41%|███████████████████▏                           | 314/767 [00:11<00:14, 30.68it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  43%|███████████████████▉                           | 326/767 [00:12<00:22, 19.74it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  44%|████████████████████▊                          | 340/767 [00:14<00:29, 14.69it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  46%|█████████████████████▊                         | 355/767 [00:16<00:32, 12.57it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  48%|██████████████████████▌                        | 369/767 [00:18<00:36, 10.97it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  72%|█████████████████████████████████▊             | 551/767 [00:26<00:09, 22.75it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  35%|████████████████▏                              | 336/973 [00:12<00:21, 29.12it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  36%|████████████████▉                              | 350/973 [00:14<00:33, 18.71it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  37%|█████████████████▌                             | 364/973 [00:15<00:41, 14.79it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  39%|██████████████████▎                            | 378/973 [00:17<00:48, 12.34it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  40%|██████████████████▉                            | 391/973 [00:19<00:55, 10.41it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  42%|███████████████████▌                           | 406/973 [00:21<00:59,  9.58it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  43%|████████████████████▎                          | 420/973 [00:23<01:03,  8.75it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  45%|████████████████████▉                          | 434/973 [00:25<01:03,  8.52it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  46%|█████████████████████▌                         | 446/973 [00:26<01:06,  7.96it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  47%|██████████████████████▏                        | 460/973 [00:28<01:05,  7.84it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  49%|██████████████████████▉                        | 475/973 [00:30<01:03,  7.79it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  75%|███████████████████████████████████            | 725/973 [00:40<00:08, 29.45it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  28%|████████████▉                                  | 131/475 [00:04<00:11, 28.67it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  49%|███████████████████████▎                       | 235/475 [00:09<00:09, 26.10it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  51%|███████████████████████▊                       | 241/475 [00:11<00:14, 16.24it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  53%|████████████████████████▊                      | 251/475 [00:12<00:18, 11.96it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  79%|████████████████████████████████████▉          | 373/475 [00:18<00:04, 23.42it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  81%|██████████████████████████████████████▎        | 387/475 [00:20<00:05, 16.92it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  29%|██████████████                                  | 97/331 [00:03<00:08, 28.86it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  33%|███████████████▌                               | 110/331 [00:05<00:12, 17.02it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  16%|███████▋                                       | 105/646 [00:03<00:19, 28.11it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  58%|███████████████████████████▍                   | 377/646 [00:15<00:09, 29.78it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  61%|████████████████████████████▍                  | 391/646 [00:16<00:12, 19.65it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  63%|█████████████████████████████▌                 | 406/646 [00:18<00:15, 15.22it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  88%|█████████████████████████████████████████▏     | 566/646 [00:24<00:02, 28.19it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  90%|██████████████████████████████████████████▎    | 582/646 [00:26<00:03, 19.49it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:   0%|                                                         | 0/267 [00:00<?, ?it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  33%|███████████████▋                               | 141/423 [00:05<00:11, 25.43it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  53%|█████████████████████████                      | 226/423 [00:10<00:09, 21.10it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  57%|██████████████████████████▉                    | 242/423 [00:12<00:12, 14.84it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:   0%|                                                         | 0/931 [00:00<?, ?it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:   2%|▋                                               | 14/931 [00:01<01:51,  8.24it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:   3%|█▍                                              | 28/931 [00:03<01:53,  7.98it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:   5%|██▏                                             | 42/931 [00:05<01:54,  7.77it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:   6%|██▉                                             | 57/931 [00:07<01:51,  7.85it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:   8%|███▋                                            | 71/931 [00:09<01:54,  7.50it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:   9%|████▎                                           | 84/931 [00:11<01:57,  7.23it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  11%|█████                                           | 98/931 [00:12<01:50,  7.53it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  12%|█████▌                                         | 111/931 [00:14<01:50,  7.44it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  14%|██████▎                                        | 126/931 [00:16<01:44,  7.73it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  15%|██████▉                                        | 138/931 [00:18<01:46,  7.43it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  16%|███████▋                                       | 152/931 [00:20<01:44,  7.49it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  18%|████████▍                                      | 166/931 [00:21<01:41,  7.54it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  19%|█████████                                      | 180/931 [00:23<01:35,  7.83it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  21%|█████████▋                                     | 193/931 [00:25<01:38,  7.52it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  69%|████████████████████████████████▏              | 638/931 [00:41<00:09, 30.35it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  69%|████████████████████████████████▋              | 647/931 [00:43<00:14, 18.96it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  71%|█████████████████████████████████▍             | 662/931 [00:45<00:18, 14.90it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  73%|██████████████████████████████████▏            | 676/931 [00:47<00:21, 11.74it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  74%|██████████████████████████████████▉            | 692/931 [00:49<00:23, 10.32it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:   0%|                                                         | 0/590 [00:00<?, ?it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:   2%|█▏                                              | 14/590 [00:01<01:18,  7.35it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:   5%|██▎                                             | 29/590 [00:03<01:11,  7.90it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:   7%|███▍                                            | 42/590 [00:05<01:13,  7.43it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  10%|████▋                                           | 57/590 [00:07<01:10,  7.56it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  12%|█████▊                                          | 71/590 [00:09<01:08,  7.60it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  16%|███████▊                                        | 40/246 [00:01<00:08, 24.01it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  20%|█████████▌                                      | 49/246 [00:03<00:15, 12.47it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  26%|████████████▍                                   | 64/246 [00:05<00:17, 10.50it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  30%|██████████████▋                                 | 75/246 [00:07<00:20,  8.54it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  48%|██████████████████████▋                        | 119/246 [00:10<00:09, 12.77it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  51%|████████████████████████                       | 126/246 [00:11<00:12,  9.70it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  42%|███████████████████▊                           | 141/334 [00:06<00:07, 24.74it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  29%|█████████████▌                                 | 238/822 [00:08<00:19, 29.73it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  31%|██████████████▍                                | 252/822 [00:09<00:29, 19.59it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  32%|███████████████▎                               | 267/822 [00:11<00:38, 14.54it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  34%|████████████████                               | 282/822 [00:13<00:43, 12.51it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  36%|████████████████▉                              | 296/822 [00:15<00:48, 10.95it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  38%|█████████████████▊                             | 311/822 [00:17<00:51,  9.88it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  40%|██████████████████▌                            | 325/822 [00:19<00:55,  9.03it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  41%|███████████████████▍                           | 340/822 [00:21<00:55,  8.71it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  19%|████████▉                                      | 101/529 [00:04<00:17, 24.31it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  22%|██████████▍                                    | 117/529 [00:06<00:24, 16.49it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  25%|███████████▊                                   | 133/529 [00:07<00:30, 13.16it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  28%|█████████████▏                                 | 149/529 [00:09<00:33, 11.48it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  31%|██████████████▋                                | 165/529 [00:11<00:34, 10.56it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  34%|████████████████                               | 181/529 [00:13<00:35,  9.80it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  37%|█████████████████▌                             | 197/529 [00:15<00:34,  9.55it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  40%|██████████████████▉                            | 213/529 [00:17<00:33,  9.50it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  43%|████████████████████▎                          | 229/529 [00:18<00:32,  9.16it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  46%|█████████████████████▊                         | 245/529 [00:20<00:32,  8.77it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  49%|███████████████████████▏                       | 261/529 [00:22<00:30,  8.83it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  52%|████████████████████████▌                      | 277/529 [00:24<00:29,  8.67it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  55%|██████████████████████████                     | 293/529 [00:26<00:27,  8.55it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  58%|███████████████████████████▍                   | 309/529 [00:28<00:26,  8.46it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  66%|███████████████████████████████▏               | 351/529 [00:31<00:14, 12.21it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:   0%|                                                         | 0/320 [00:00<?, ?it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:   2%|█                                                | 7/320 [00:01<01:27,  3.58it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  73%|██████████████████████████████████▏            | 233/320 [00:11<00:03, 24.91it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  78%|████████████████████████████████████▊          | 251/320 [00:16<00:06, 11.46it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:   0%|                                                         | 0/660 [00:00<?, ?it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:   2%|█▏                                              | 16/660 [00:02<01:21,  7.94it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  20%|█████████▌                                     | 134/660 [00:08<00:24, 21.42it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  23%|██████████▌                                    | 149/660 [00:10<00:32, 15.57it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  25%|███████████▋                                   | 164/660 [00:11<00:39, 12.41it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  27%|████████████▋                                  | 179/660 [00:13<00:42, 11.28it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  29%|█████████████▊                                 | 194/660 [00:15<00:46, 10.02it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  32%|██████████████▉                                | 209/660 [00:17<00:49,  9.13it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  34%|███████████████▉                               | 223/660 [00:19<00:51,  8.50it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  35%|████████████████▌                              | 232/660 [00:21<00:57,  7.49it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  37%|█████████████████▌                             | 246/660 [00:23<00:55,  7.43it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  39%|██████████████████▌                            | 260/660 [00:25<00:53,  7.52it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  41%|███████████████████▎                           | 272/660 [00:27<00:54,  7.07it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  43%|████████████████████▎                          | 286/660 [00:28<00:51,  7.31it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  58%|███████████████████████████▎                   | 383/660 [00:33<00:16, 16.71it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  52%|████████████████████████▍                      | 233/448 [00:08<00:07, 27.81it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  56%|██████████████████████████                     | 249/448 [00:10<00:10, 19.29it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:   3%|█▍                                             | 32/1004 [00:01<00:31, 31.35it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  11%|█████▎                                        | 115/1004 [00:05<00:40, 21.90it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  18%|████████▎                                     | 182/1004 [00:09<00:39, 21.00it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  20%|█████████                                     | 197/1004 [00:11<00:53, 14.97it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  34%|███████████████▋                              | 343/1004 [00:17<00:25, 25.45it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  35%|████████████████                              | 350/1004 [00:19<00:41, 15.71it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  36%|████████████████▋                             | 365/1004 [00:21<00:50, 12.74it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  38%|█████████████████▎                            | 379/1004 [00:23<00:57, 10.83it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  39%|██████████████████                            | 393/1004 [00:25<01:04,  9.47it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  41%|██████████████████▋                           | 408/1004 [00:27<01:07,  8.79it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  42%|███████████████████▍                          | 423/1004 [00:29<01:06,  8.69it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  43%|███████████████████▉                          | 435/1004 [00:31<01:11,  8.01it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  45%|████████████████████▌                         | 448/1004 [00:33<01:12,  7.63it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  46%|█████████████████████                         | 461/1004 [00:35<01:15,  7.23it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  47%|█████████████████████▊                        | 475/1004 [00:37<01:13,  7.21it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  49%|██████████████████████▎                       | 488/1004 [00:38<01:11,  7.26it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  50%|███████████████████████                       | 502/1004 [00:40<01:10,  7.14it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  51%|███████████████████████▋                      | 516/1004 [00:42<01:05,  7.48it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  53%|████████████████████████▎                     | 530/1004 [00:44<01:03,  7.52it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  54%|████████████████████████▉                     | 545/1004 [00:46<00:59,  7.76it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  56%|█████████████████████████▋                    | 560/1004 [00:48<00:57,  7.77it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  57%|██████████████████████████▎                   | 573/1004 [00:50<00:59,  7.23it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  58%|██████████████████████████▉                   | 587/1004 [00:52<00:59,  7.00it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  60%|███████████████████████████▍                  | 598/1004 [00:54<01:02,  6.48it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  29%|█████████████▍                                 | 220/767 [00:08<00:21, 25.02it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  31%|██████████████▌                                | 237/767 [00:12<00:41, 12.87it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  62%|█████████████████████████████                  | 474/767 [00:22<00:11, 25.64it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  72%|█████████████████████████████████▊             | 551/767 [00:26<00:09, 23.37it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  74%|██████████████████████████████████▋            | 567/767 [00:28<00:11, 17.70it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  15%|███████                                         | 90/610 [00:02<00:16, 31.46it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  17%|████████▏                                      | 106/610 [00:04<00:27, 18.60it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  40%|███████████████████                            | 247/610 [00:11<00:16, 22.02it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  74%|██████████████████████████████████▉            | 233/314 [00:09<00:03, 26.06it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  78%|████████████████████████████████████▌          | 244/314 [00:11<00:04, 16.49it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:   0%|                                                         | 0/406 [00:00<?, ?it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:   2%|█▏                                              | 10/406 [00:01<01:11,  5.50it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  20%|█████████▌                                      | 81/406 [00:05<00:17, 18.46it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  24%|███████████▎                                    | 96/406 [00:07<00:22, 13.97it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  27%|████████████▊                                  | 111/406 [00:09<00:26, 11.20it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  41%|███████████████████▍                           | 168/406 [00:13<00:15, 15.05it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  70%|█████████████████████████████████              | 286/406 [00:18<00:05, 23.68it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  74%|██████████████████████████████████▋            | 300/406 [00:20<00:06, 17.02it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  78%|████████████████████████████████████▍          | 315/406 [00:22<00:06, 13.67it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  81%|██████████████████████████████████████▏        | 330/406 [00:24<00:06, 11.39it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  33%|███████████████▎                               | 149/457 [00:05<00:11, 26.87it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:   0%|                                                         | 0/255 [00:00<?, ?it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:   5%|██▎                                             | 12/255 [00:01<00:35,  6.77it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  11%|█████▎                                          | 28/255 [00:03<00:28,  8.06it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  27%|█████████████▏                                  | 70/255 [00:06<00:14, 13.05it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  30%|██████████████▍                                 | 77/255 [00:08<00:19,  9.27it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  36%|█████████████████▌                              | 93/255 [00:10<00:18,  8.88it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  71%|█████████████████████████████████▌             | 182/255 [00:14<00:03, 18.58it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  30%|██████████████                                 | 217/723 [00:08<00:19, 26.14it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  31%|██████████████▋                                | 226/723 [00:10<00:29, 17.00it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  33%|███████████████▍                               | 238/723 [00:12<00:37, 12.87it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  53%|████████████████████████▉                      | 384/723 [00:18<00:14, 23.21it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  54%|█████████████████████████▍                     | 391/723 [00:20<00:22, 14.89it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  56%|██████████████████████████▎                    | 405/723 [00:22<00:25, 12.33it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  70%|████████████████████████████████▉              | 507/723 [00:27<00:10, 20.78it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  71%|█████████████████████████████████▍             | 514/723 [00:29<00:15, 13.58it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  77%|████████████████████████████████████▎          | 558/723 [00:32<00:10, 15.27it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  79%|█████████████████████████████████████▎         | 574/723 [00:34<00:11, 12.62it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "WARNING:root:Buffer size reduced to 8 for iteration.\n",
      "Tokenizing sentences:  80%|█████████████████████████████████████▌         | 577/723 [00:37<00:19,  7.44it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "WARNING:root:Buffer size reduced to 8 for iteration.\n",
      "Tokenizing sentences:  81%|█████████████████████████████████████▉         | 583/723 [00:40<00:25,  5.40it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "WARNING:root:Buffer size reduced to 8 for iteration.\n",
      "Tokenizing sentences:   6%|███                                             | 31/495 [00:00<00:12, 36.92it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:   9%|████▏                                           | 43/495 [00:02<00:33, 13.61it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  12%|█████▌                                          | 58/495 [00:04<00:42, 10.35it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  15%|██████▉                                         | 72/495 [00:06<00:45,  9.33it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  18%|████████▍                                       | 87/495 [00:08<00:47,  8.62it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  21%|█████████▋                                     | 102/495 [00:10<00:47,  8.30it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:   0%|                                                         | 0/279 [00:00<?, ?it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:   5%|██▌                                             | 15/279 [00:01<00:32,  8.02it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  10%|████▉                                           | 29/279 [00:03<00:31,  7.95it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  16%|███████▌                                        | 44/279 [00:05<00:30,  7.65it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  21%|██████████▏                                     | 59/279 [00:07<00:28,  7.84it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  26%|████████████▌                                   | 73/279 [00:09<00:26,  7.76it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  13%|█████▉                                        | 145/1123 [00:04<00:30, 32.37it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  16%|███████▌                                      | 185/1123 [00:07<00:41, 22.56it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  18%|████████                                      | 197/1123 [00:09<00:59, 15.47it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  19%|████████▋                                     | 213/1123 [00:11<01:11, 12.78it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  20%|█████████▍                                    | 229/1123 [00:13<01:18, 11.37it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  45%|████████████████████▋                         | 505/1123 [00:25<00:23, 26.41it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  56%|█████████████████████████▋                    | 628/1123 [00:31<00:19, 24.92it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  64%|█████████████████████████████▌                | 721/1123 [00:36<00:18, 21.91it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  66%|██████████████████████████████▏               | 737/1123 [00:38<00:23, 16.35it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  67%|██████████████████████████████▊               | 752/1123 [00:40<00:27, 13.35it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  67%|██████████████████████████████▉               | 754/1123 [00:42<00:40,  9.13it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  68%|███████████████████████████████▍              | 769/1123 [00:44<00:40,  8.77it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  70%|████████████████████████████████              | 784/1123 [00:46<00:40,  8.29it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  78%|███████████████████████████████████▊          | 875/1123 [00:50<00:13, 18.49it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  79%|████████████████████████████████████▍         | 891/1123 [00:52<00:16, 14.39it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  81%|█████████████████████████████████████         | 906/1123 [00:54<00:18, 11.94it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  94%|██████████████████████████████████████████▍  | 1060/1123 [01:01<00:02, 22.21it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:   0%|                                                         | 0/605 [00:00<?, ?it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:   2%|█                                               | 14/605 [00:01<01:22,  7.12it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:   4%|██▏                                             | 27/605 [00:03<01:20,  7.18it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:   7%|███▎                                            | 42/605 [00:05<01:14,  7.53it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:   9%|████▌                                           | 57/605 [00:07<01:09,  7.89it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  12%|█████▌                                          | 70/605 [00:09<01:12,  7.41it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  14%|██████▋                                         | 85/605 [00:11<01:07,  7.68it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  34%|████████████████▏                              | 208/605 [00:16<00:18, 21.24it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  75%|███████████████████████████████████▏           | 453/605 [00:26<00:05, 28.75it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  34%|███████████████▉                               | 206/608 [00:07<00:13, 29.83it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  36%|█████████████████                              | 221/608 [00:09<00:20, 18.56it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  49%|███████████████████████▏                       | 300/608 [00:14<00:15, 20.19it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  59%|███████████████████████████▊                   | 359/608 [00:17<00:13, 17.96it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:   0%|                                                         | 0/306 [00:00<?, ?it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:   5%|██▏                                             | 14/306 [00:01<00:34,  8.49it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:   9%|████▌                                           | 29/306 [00:03<00:34,  8.02it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  14%|██████▉                                         | 44/306 [00:05<00:33,  7.75it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  19%|█████████▎                                      | 59/306 [00:07<00:31,  7.84it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  24%|███████████▌                                    | 74/306 [00:09<00:30,  7.63it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  29%|█████████████▉                                  | 89/306 [00:11<00:27,  7.94it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  34%|███████████████▊                               | 103/306 [00:12<00:25,  8.10it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  37%|█████████████████▌                             | 114/306 [00:14<00:25,  7.57it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  42%|███████████████████▉                           | 130/306 [00:16<00:22,  7.73it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:   0%|                                                         | 0/313 [00:00<?, ?it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  70%|████████████████████████████████▋              | 218/313 [00:09<00:03, 27.91it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  30%|█████████████▉                                 | 198/665 [00:06<00:16, 28.91it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  31%|██████████████▍                                | 205/665 [00:08<00:27, 16.48it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  57%|██████████████████████████▌                    | 376/665 [00:16<00:10, 27.74it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  65%|██████████████████████████████▋                | 434/665 [00:19<00:11, 20.58it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  14%|██████▋                                         | 60/431 [00:01<00:11, 32.70it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  67%|███████████████████████████████▌               | 290/431 [00:11<00:05, 26.25it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  25%|███████████▊                                   | 159/631 [00:05<00:15, 29.81it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  60%|████████████████████████████▎                  | 380/631 [00:14<00:08, 28.36it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  15%|███████▏                                        | 59/392 [00:01<00:10, 32.36it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  19%|████████▉                                       | 73/392 [00:03<00:18, 17.15it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  22%|██████████▋                                     | 87/392 [00:05<00:24, 12.23it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  26%|████████████                                   | 101/392 [00:07<00:28, 10.15it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  29%|█████████████▋                                 | 114/392 [00:09<00:30,  9.08it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  39%|██████████████████▏                            | 152/392 [00:12<00:19, 12.14it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  42%|███████████████████▊                           | 165/392 [00:13<00:22, 10.27it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  46%|█████████████████████▍                         | 179/392 [00:15<00:22,  9.51it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:   0%|                                                         | 0/469 [00:00<?, ?it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:   3%|█▌                                              | 15/469 [00:01<00:56,  8.10it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:   6%|██▉                                             | 29/469 [00:03<00:55,  7.88it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:   9%|████▌                                           | 44/469 [00:05<00:54,  7.74it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  13%|██████                                          | 59/469 [00:07<00:52,  7.77it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  16%|███████▍                                        | 73/469 [00:09<00:50,  7.79it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  18%|████████▍                                       | 83/469 [00:11<00:54,  7.12it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  27%|████████████▋                                  | 126/469 [00:14<00:30, 11.36it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  41%|███████████████████▏                           | 192/469 [00:17<00:16, 16.45it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  43%|████████████████████▍                          | 204/469 [00:19<00:21, 12.26it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  46%|█████████████████████▋                         | 217/469 [00:21<00:24, 10.39it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  49%|██████████████████████▉                        | 229/469 [00:23<00:25,  9.32it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  69%|████████████████████████████████▎              | 305/444 [00:11<00:05, 27.54it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:   4%|██▏                                             | 30/674 [00:00<00:19, 33.32it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:   7%|███▏                                            | 45/674 [00:02<00:44, 14.22it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:   9%|████▏                                           | 58/674 [00:04<00:57, 10.63it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  11%|█████▏                                          | 73/674 [00:06<01:04,  9.38it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  13%|██████▎                                         | 88/674 [00:08<01:05,  8.97it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  15%|███████                                        | 102/674 [00:10<01:07,  8.43it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  17%|████████                                       | 116/674 [00:12<01:11,  7.83it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  19%|█████████▏                                     | 131/674 [00:14<01:11,  7.58it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  22%|██████████▏                                    | 146/674 [00:16<01:10,  7.53it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  23%|███████████                                    | 158/674 [00:18<01:11,  7.24it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  56%|██████████████████████████▎                    | 377/674 [00:27<00:11, 25.06it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  58%|███████████████████████████▍                   | 393/674 [00:29<00:16, 17.33it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  23%|██████████▉                                    | 134/577 [00:04<00:15, 29.14it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  35%|████████████████▎                              | 200/577 [00:08<00:16, 22.54it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:   4%|██                                              | 36/831 [00:01<00:35, 22.25it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:   6%|██▉                                             | 51/831 [00:03<00:58, 13.36it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:   8%|███▊                                            | 66/831 [00:05<01:11, 10.65it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  10%|████▌                                           | 79/831 [00:07<01:27,  8.56it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  11%|█████▍                                          | 94/831 [00:09<01:28,  8.34it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  13%|██████                                         | 108/831 [00:11<01:28,  8.21it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  15%|██████▉                                        | 122/831 [00:13<01:32,  7.67it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  16%|███████▋                                       | 137/831 [00:15<01:28,  7.80it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  18%|████████▍                                      | 150/831 [00:17<01:33,  7.29it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  47%|██████████████████████▎                        | 394/831 [00:27<00:16, 26.39it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  49%|███████████████████████▏                       | 410/831 [00:29<00:23, 18.30it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  51%|███████████████████████▉                       | 423/831 [00:31<00:29, 13.87it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  53%|████████████████████████▊                      | 439/831 [00:33<00:32, 11.90it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  54%|█████████████████████████▎                     | 448/831 [00:35<00:39,  9.58it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  56%|██████████████████████████▏                    | 464/831 [00:36<00:39,  9.38it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  64%|██████████████████████████████                 | 532/831 [00:40<00:18, 16.29it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  15%|███████▎                                        | 37/242 [00:01<00:08, 23.91it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  52%|████████████████████████▋                      | 127/242 [00:06<00:05, 22.86it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  59%|███████████████████████████▊                   | 143/242 [00:08<00:05, 16.51it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  64%|██████████████████████████████▎                | 156/242 [00:10<00:06, 12.85it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  40%|██████████████████▉                            | 170/423 [00:05<00:08, 29.33it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  83%|██████████████████████████████████████▉        | 350/423 [00:14<00:02, 28.79it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  36%|████████████████▉                              | 187/518 [00:06<00:10, 30.52it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  39%|██████████████████▍                            | 203/518 [00:08<00:15, 19.96it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  42%|███████████████████▊                           | 219/518 [00:10<00:19, 14.99it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  45%|█████████████████████▎                         | 235/518 [00:12<00:22, 12.63it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  55%|█████████████████████████▋                     | 283/518 [00:14<00:14, 16.08it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  58%|███████████████████████████▏                   | 299/518 [00:16<00:16, 13.18it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  61%|████████████████████████████▌                  | 315/518 [00:18<00:17, 11.43it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  64%|██████████████████████████████                 | 331/518 [00:20<00:17, 10.81it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  67%|███████████████████████████████▍               | 347/518 [00:22<00:16, 10.10it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  70%|████████████████████████████████▉              | 363/518 [00:24<00:15,  9.71it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  73%|██████████████████████████████████▍            | 379/518 [00:25<00:14,  9.50it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  27%|████████████▌                                  | 102/382 [00:03<00:11, 24.43it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  51%|███████████████████████▋                       | 193/382 [00:08<00:07, 24.56it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  54%|█████████████████████████▌                     | 208/382 [00:10<00:10, 16.20it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  57%|██████████████████████████▌                    | 216/382 [00:12<00:14, 11.77it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  60%|████████████████████████████                   | 228/382 [00:14<00:15,  9.80it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  78%|████████████████████████████████████▊          | 299/382 [00:17<00:04, 16.84it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  82%|██████████████████████████████████████▌        | 313/382 [00:19<00:05, 13.35it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:   0%|                                                         | 0/566 [00:00<?, ?it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:   2%|█▏                                              | 14/566 [00:01<01:18,  7.01it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:   5%|██▎                                             | 28/566 [00:03<01:10,  7.69it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:   7%|███▌                                            | 42/566 [00:05<01:09,  7.51it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  10%|████▊                                           | 57/566 [00:07<01:05,  7.78it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  13%|██████                                          | 72/566 [00:09<01:05,  7.54it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  15%|███████▍                                        | 87/566 [00:11<01:02,  7.64it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  18%|████████▍                                      | 102/566 [00:13<01:01,  7.61it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  21%|█████████▋                                     | 117/566 [00:15<00:58,  7.62it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  23%|██████████▉                                    | 131/566 [00:17<00:56,  7.72it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  26%|████████████                                   | 145/566 [00:18<00:54,  7.74it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  27%|████████████▋                                  | 153/566 [00:20<01:01,  6.73it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  30%|█████████████▉                                 | 168/566 [00:22<00:56,  7.07it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  31%|██████████████▌                                | 175/566 [00:24<01:07,  5.81it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  49%|███████████████████████                        | 278/566 [00:29<00:15, 18.49it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  50%|███████████████████████▌                       | 283/566 [00:31<00:22, 12.74it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  58%|███████████████████████████▎                   | 329/566 [00:34<00:15, 15.50it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  61%|████████████████████████████▋                  | 345/566 [00:36<00:17, 12.71it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  20%|█████████▌                                     | 124/608 [00:04<00:16, 28.92it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  23%|██████████▊                                    | 140/608 [00:06<00:25, 18.15it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  53%|████████████████████████▉                      | 322/608 [00:15<00:12, 23.70it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  76%|███████████████████████████████████▊           | 220/289 [00:08<00:02, 28.23it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:   0%|                                                         | 0/522 [00:00<?, ?it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  41%|███████████████████▎                           | 214/522 [00:09<00:10, 28.41it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  44%|████████████████████▌                          | 228/522 [00:11<00:15, 18.53it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  52%|████████████████████████▍                      | 271/522 [00:14<00:13, 18.03it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  81%|██████████████████████████████████████         | 423/522 [00:21<00:04, 20.48it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  66%|███████████████████████████████                | 182/275 [00:06<00:03, 29.23it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:   0%|                                                         | 0/420 [00:00<?, ?it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:   0%|                                                         | 0/308 [00:00<?, ?it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:   5%|██▏                                             | 14/308 [00:02<00:43,  6.78it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:   6%|██▋                                             | 17/308 [00:03<01:12,  3.99it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  11%|█████▏                                          | 33/308 [00:05<00:46,  5.89it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  15%|███████▎                                        | 47/308 [00:07<00:39,  6.68it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  20%|█████████▋                                      | 62/308 [00:09<00:34,  7.03it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  25%|████████████                                    | 77/308 [00:11<00:31,  7.23it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  30%|██████████████▏                                 | 91/308 [00:13<00:29,  7.34it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  34%|███████████████▊                               | 104/308 [00:15<00:29,  7.02it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  38%|█████████████████▋                             | 116/308 [00:17<00:28,  6.82it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  42%|███████████████████▊                           | 130/308 [00:19<00:24,  7.12it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  47%|█████████████████████▉                         | 144/308 [00:21<00:23,  7.08it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  52%|████████████████████████▎                      | 159/308 [00:22<00:20,  7.33it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  56%|██████████████████████████▍                    | 173/308 [00:24<00:18,  7.34it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  16%|███████▋                                       | 100/610 [00:03<00:18, 27.26it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  28%|█████████████                                  | 170/610 [00:07<00:19, 22.31it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  30%|██████████████▏                                | 184/610 [00:09<00:26, 16.12it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  32%|███████████████▎                               | 198/610 [00:11<00:31, 13.12it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  35%|████████████████▎                              | 212/610 [00:12<00:35, 11.25it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  37%|█████████████████▎                             | 225/610 [00:14<00:39,  9.63it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  43%|████████████████████▎                          | 263/610 [00:17<00:27, 12.61it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  45%|█████████████████████▎                         | 276/610 [00:19<00:32, 10.41it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "Tokenizing sentences:  47%|██████████████████████▏                        | 288/610 [00:21<00:35,  9.02it/s]WARNING:root:Buffer size reduced to 16 for iteration.\n",
      "                                                                                                            \r"
     ]
    }
   ],
   "source": [
    "data = pd.DataFrame(columns = [\"id\", \"sentence\", \"word\", \"start\", \"end\", \"regex_rule\", \"true_label\"])\n",
    "\n",
    "for record in json_data:\n",
    "    text = record[\"data\"][\"text\"].replace('\"', \" \").replace(\"'\", \" \")\n",
    "    \n",
    "    tokens: List[str] = nltk_lib.tokenize.word_tokenize(text, language='czech', preserve_line=False)\n",
    "    offsets = [item for sublist in get_original_spans(tokens, text) for item in sublist]\n",
    "    tokens_with_offsets: List[Dict[str, Any]] = [{\"word\": word, \n",
    "                                                  \"start\": offset[0], \n",
    "                                                  \"end\": offset[1]} for word, offset in zip(tokens, offsets)]\n",
    "    \n",
    "    temp = pd.DataFrame(tokens_with_offsets, \n",
    "                        columns=[\"id\", \"sentence\", \"word\", \"start\", \"end\", \"regex_rule\", \"true_label\"])\n",
    "    temp[\"id\"] = record[\"id\"]\n",
    "    label_words(record, temp)\n",
    "\n",
    "    satisfies_regex_rule(text, temp)\n",
    "\n",
    "    sentences = clini_tokenize(text)\n",
    "    assign_sentence_id(temp, sentences)\n",
    "\n",
    "    data = pd.concat([data, temp], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e8c7c0c1-b14f-4a04-a9f0-e5b32a9ecb81",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['sentence'] = data['sentence'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "45f61470-4c4d-4228-878b-cebe98db6cbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 53767 entries, 0 to 53766\n",
      "Data columns (total 7 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   id          53767 non-null  object\n",
      " 1   sentence    53767 non-null  int64 \n",
      " 2   word        53767 non-null  object\n",
      " 3   start       53767 non-null  object\n",
      " 4   end         53767 non-null  object\n",
      " 5   regex_rule  53767 non-null  object\n",
      " 6   true_label  53767 non-null  object\n",
      "dtypes: int64(1), object(6)\n",
      "memory usage: 2.9+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "54fd3f5e-2b88-4438-af0e-e3ed10f6671f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>word</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>regex_rule</th>\n",
       "      <th>true_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Ke</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>kontrole</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>,</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>k</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>pokračování</td>\n",
       "      <td>15</td>\n",
       "      <td>26</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  id  sentence         word start end regex_rule true_label\n",
       "0  3         0           Ke     0   2          O          O\n",
       "1  3         0     kontrole     3  11          O          O\n",
       "2  3         0            ,    11  12          O          O\n",
       "3  3         0            k    13  14          O          O\n",
       "4  3         0  pokračování    15  26          O          O"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "21b4cb2c-ffe7-4c70-8ca9-09724e059baa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows with NaN values: []\n"
     ]
    }
   ],
   "source": [
    "rows_with_NaN = data.isnull().any(axis=1)[data.isnull().any(axis=1)].index.tolist()\n",
    "print(\"Rows with NaN values:\", rows_with_NaN )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e007c39a-9e35-438c-8557-c19eb2559f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "regex_mapping = data[[\"id\", \"sentence\", \"start\", \"end\", \"regex_rule\"]].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "35b99c32-facc-42d6-8f29-4616a1829422",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(columns=[\"regex_rule\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3cc9f3ae-e0c2-43bf-b02d-072ea1cabf89",
   "metadata": {},
   "outputs": [],
   "source": [
    "regex_mapping.to_csv(\"regex_mapping.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6319265b-f018-426e-9263-f7587b93b384",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(\"patient_records.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
